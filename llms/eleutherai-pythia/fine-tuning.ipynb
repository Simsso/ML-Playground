{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"70m\"  # or 2.8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  f\"EleutherAI/pythia-{model_size}-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=f\"./pythia-{model_size}-deduped/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  f\"EleutherAI/pythia-{model_size}-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=f\"./pythia-{model_size}-deduped/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenizer(\"Training example #1 is continuing just this text. That's all.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[47416,  1650,  1852,    18,   310, 11440,   816,   436,  2505,    15,\n",
       "          2064,   434,   512,    15,   187,   187,    34,    27,   187,   187,\n",
       "            42,  1158,   368,  1472,   987,    15,   309,  1158,   368,  1472]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This actually samples from the model and continues the inputs sequence.\n",
    "model.generate(**train_data, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 50304])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is one parallel forward pass through the model, useful for training / perplexity on a sentence.\n",
    "# Output logits have the shape (batch, num_tokens, vocab_size)\n",
    "model(**train_data).logits.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab is ~50k. Tradeoff between memory consumption (long seq len) and more model parameters.\n",
    "\n",
    "Last layer parameters in this case: $50304 \\times 512 = 25M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50304, 512)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_modules())['gpt_neox.embed_in']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Or is it shared with the emb space?) Comparison of `gpt_neox.embed_in` and `embed_out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=50304, bias=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_modules())['embed_out']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First and last layer inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0324,  0.0372, -0.0339,  ...,  0.0141, -0.0041,  0.0731],\n",
       "         [-0.0323,  0.0438, -0.0388,  ..., -0.0005,  0.0452,  0.0865],\n",
       "         [ 0.0770, -0.0487,  0.0957,  ...,  0.0418, -0.0245,  0.0255],\n",
       "         ...,\n",
       "         [ 0.0094,  0.0218, -0.0342,  ...,  0.0123,  0.0355,  0.0566],\n",
       "         [-0.0061,  0.0197, -0.0467,  ...,  0.0004, -0.0008,  0.0076],\n",
       "         [ 0.0226, -0.0023, -0.0380,  ...,  0.0126,  0.0422,  0.0599]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0308, -0.0087,  0.0353,  ...,  0.0028,  0.0612, -0.0313],\n",
       "         [-0.0188,  0.0053, -0.0140,  ...,  0.0042, -0.0359, -0.0329],\n",
       "         [-0.0215, -0.0540, -0.0469,  ..., -0.0137,  0.0544, -0.0139],\n",
       "         ...,\n",
       "         [-0.0400,  0.0041, -0.0577,  ..., -0.0170,  0.0236, -0.0073],\n",
       "         [-0.0121, -0.0004,  0.0441,  ..., -0.0316, -0.0187,  0.0260],\n",
       "         [ 0.0440,  0.0214,  0.0234,  ..., -0.0043, -0.0058, -0.0082]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out_layer = dict(model.named_modules())['embed_out']\n",
    "emb_in_layer = dict(model.named_modules())['gpt_neox.embed_in']\n",
    "\n",
    "list(emb_out_layer.parameters())[0], list(emb_in_layer.parameters())[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation_i (512) @ large_weight_matrix (512x50k) ==> logits\n",
    "\n",
    "May --> month\n",
    "May --> ask for permission\n",
    "\"The word to greet is ____\" --> logits(\"hi\") --> high value; logits(\"hello\") --> high value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb_mat = list(emb_out_layer.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(word: str) -> list[str]:\n",
    "    hello_emb = vocab_emb_mat[tokenizer(word)['input_ids'][0]]\n",
    "    sim_scores = vocab_emb_mat @ hello_emb\n",
    "    top_similar = torch.argsort(sim_scores, descending=True)[:20]\n",
    "    return [tokenizer.decode([s]) for s in top_similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa | aaa | aaaa | ais | aan | ae | a | aea | uu | af | aaaaaaaa | aq | ua | avat | ana | ea | aha | afa | eed | ira\n"
     ]
    }
   ],
   "source": [
    "print(*get_similar_words(\"aa\"), sep=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | TestCase | Tests | Testing | test |  Test |  Tests | Mock | tests | Unit | Ignore | testing | Suite | Sample | Trial | TEST | Rule | ittest | Assert | Override\n"
     ]
    }
   ],
   "source": [
    "print(*get_similar_words(\"Test\"), sep=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello | Hi | hello | Welcome | Dear | Hey | Wow |  Hello | Excuse | Nice | Looks | Yesterday | Bye | Sorry | Alright | Excellent | Been | ====== | Yeah | noreply\n"
     ]
    }
   ],
   "source": [
    "print(*get_similar_words(\"Hello\"), sep=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May | April | June | October | February | March | November | July | December | September | August | January | Feb | Apr | Aug | Sept | Nov | Oct | Jun | Jan\n"
     ]
    }
   ],
   "source": [
    "print(*get_similar_words(\"May\"), sep=\" | \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer([\n",
    "        \"hi\",\n",
    "        \"how are you\",\n",
    "        \"this is\"\n",
    "    ],\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding='longest',\n",
    "    return_attention_mask=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[5801,    0,    0],\n",
       "        [5430,  403,  368],\n",
       "        [2520,  310,    0]]), 'attention_mask': tensor([[1, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 0]])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = result[\"input_ids\"]\n",
    "batch_size = input_tokens.shape[0]\n",
    "input_tokens = torch.concat(\n",
    "    [\n",
    "        torch.tensor(tokenizer.bos_token_id).expand((batch_size, 1)),\n",
    "        input_tokens,\n",
    "    ],\n",
    "    axis=-1)\n",
    "target_tokens = torch.concat([\n",
    "        input_tokens[:, 1:],\n",
    "        torch.tensor(tokenizer.eos_token_id).expand((batch_size, 1)),\n",
    "    ],\n",
    "    axis=-1)\n",
    "result[\"input_ids\"] = input_tokens\n",
    "result[\"target_ids\"] = target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0,    0, 5801,    0,    0],\n",
       "        [   0,    0, 5430,  403,  368],\n",
       "        [   0,    0, 2520,  310,    0]]), 'attention_mask': tensor([[1, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 0]]), 'target_ids': tensor([[   0, 5801,    0,    0,    0],\n",
       "        [   0, 5430,  403,  368,    0],\n",
       "        [   0, 2520,  310,    0,    0]])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenizer(\"Training example #1 is continuing just this text. That's all.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1650,  1852,    18,   310, 11440,   816,   436,  2505,    15,  2064,\n",
       "           434,   512,    15,     0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift input by one so we train on \"next word prediction\".\n",
    "# Add the EOS token so we have a target for the last word.\n",
    "target = torch.concat([\n",
    "    train_data['input_ids'][:,1:], \n",
    "    torch.tensor([[tokenizer.eos_token_id]])\n",
    "    ], axis=-1)\n",
    "target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of text in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" example #1 is continuing just this text. That's all.<|endoftext|>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "ce_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    opt.zero_grad()\n",
    "    logits = model(**train_data).logits.permute([0, 2, 1])\n",
    "    loss = ce_loss_fn(logits, target)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x136282460>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre_trained = GPTNeoXForCausalLM.from_pretrained(\n",
    "  f\"EleutherAI/pythia-{model_size}-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=f\"./pythia-{model_size}-deduped/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, text: str) -> str:\n",
    "    tokens = model.generate(\n",
    "        **tokenizer(text, return_tensors=\"pt\"),\n",
    "        pad_token_id=tokenizer.eos_token_id, max_length=30)\n",
    "    return tokenizer.decode(tokens[0])\n",
    "\n",
    "def generate_sxs(text: str) -> dict[str, str]:\n",
    "    return {\n",
    "        'fine-tuned': generate(model, text),\n",
    "        'pre-trained': generate(model_pre_trained, text),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine-tuned': \"Training example #1 is continuing just this text. That's all.<|endoftext|>\",\n",
       " 'pre-trained': 'TrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTrainingTraining'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sxs(\"Training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we fine-tuned it! For everything else it does bs (?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine-tuned': \"Hi there is a great question. That's all.<|endoftext|>\",\n",
       " 'pre-trained': 'Hi there is a question of a question of a question of a question of a question of a question of a question of a question of a question of'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sxs(\"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine-tuned': 'Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi Hi',\n",
       " 'pre-trained': 'HiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHiHi'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sxs(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine-tuned': \"Continuing this text. That's all.<|endoftext|>\",\n",
       " 'pre-trained': 'Continuing the\\n\\n“The only thing that I can do is to get the best of my ability and the best of my ability.”\\n\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sxs(\"Continuing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fine-tuned': \"Continue this sequence. That's all.<|endoftext|>\",\n",
       " 'pre-trained': 'Continue this sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of sequence of'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sxs(\"Continue this sequence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper title: fine-tuning with one random sentence can improve sequence termination capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
